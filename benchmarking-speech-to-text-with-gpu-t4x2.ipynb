{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libaries for benchmarking speech to text with GPU T4x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T15:16:07.275825Z",
     "iopub.status.busy": "2024-12-15T15:16:07.274945Z",
     "iopub.status.idle": "2024-12-15T15:17:06.960892Z",
     "shell.execute_reply": "2024-12-15T15:17:06.959806Z",
     "shell.execute_reply.started": "2024-12-15T15:16:07.275786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cuda-python in /opt/conda/lib/python3.10/site-packages (12.6.2.post1)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-p8zsrk8l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-p8zsrk8l\n",
      "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper==20240930) (3.15.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2024.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20240930) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.57.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: groq in /opt/conda/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/conda/lib/python3.10/site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n"
     ]
    }
   ],
   "source": [
    "# Install torch with CUDA support\n",
    "!pip install cuda-python\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install Whisper\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "\n",
    "# Install dotenv for environment variable management\n",
    "!pip install python-dotenv\n",
    "\n",
    "# Install OpenAI Python client library\n",
    "!pip install openai\n",
    "\n",
    "# Install Groq library\n",
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T15:17:06.963344Z",
     "iopub.status.busy": "2024-12-15T15:17:06.963008Z",
     "iopub.status.idle": "2024-12-15T15:17:06.969701Z",
     "shell.execute_reply": "2024-12-15T15:17:06.968818Z",
     "shell.execute_reply.started": "2024-12-15T15:17:06.963315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to Text code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-15T15:17:06.971984Z",
     "iopub.status.busy": "2024-12-15T15:17:06.971340Z",
     "iopub.status.idle": "2024-12-15T15:17:07.008546Z",
     "shell.execute_reply": "2024-12-15T15:17:07.007930Z",
     "shell.execute_reply.started": "2024-12-15T15:17:06.971941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import whisper\n",
    "import torch\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "\n",
    "# Ignore the warning when using CPU\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
    "\n",
    "# Load the API_KEY. Replace with your API Key\n",
    "api_key = \"OPENAI_API_KEY\"\n",
    "groq_api_key = \"GROQ_API_KEY\"\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Initialize the Groq client\n",
    "groq_client = Groq(api_key=groq_api_key)\n",
    "\n",
    "# Function to transcribe an audio file using OpenAI API with the whisper large model\n",
    "def transcribe_audio_with_openai(audio_file: str) -> str:\n",
    "    try:\n",
    "        with open(audio_file, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=file\n",
    "            )\n",
    "        return transcription.text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to transcribe an audio file using Groq API with the whisper large model\n",
    "def transcribe_audio_with_groq(audio_file: str) -> str:\n",
    "    try:\n",
    "        with open(audio_file, \"rb\") as file:\n",
    "            transcription = groq_client.audio.transcriptions.create(\n",
    "                file=(audio_file, file.read()),\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "        return transcription.text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "# Function to transcribe an audio file using Whisper model running locally\n",
    "def transcribe_audio_with_whisper_local(audio_file: str) -> str:\n",
    "    try:\n",
    "        # Check for CUDA availability, otherwise fallback to CPU\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Load the Whisper large model - turbo version is optimized for speed\n",
    "        model = whisper.load_model(\"turbo\", device=device)\n",
    "\n",
    "        # Perform transcription\n",
    "        if(device == \"cpu\"):\n",
    "            result = model.transcribe(audio_file, fp16=False)\n",
    "        else:\n",
    "            result = model.transcribe(audio_file, fp16=True)\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T15:17:07.009676Z",
     "iopub.status.busy": "2024-12-15T15:17:07.009436Z",
     "iopub.status.idle": "2024-12-15T15:19:06.748634Z",
     "shell.execute_reply": "2024-12-15T15:19:06.747564Z",
     "shell.execute_reply.started": "2024-12-15T15:17:07.009652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_0.wav...\n",
      "OpenAI Transcription: 느낌이 확실히 나죠? 그래서 앞코가 조금 더 나는 동그란 타입을 원합니다 하시는 분들은 저희 소가죽 첼시 앵클부츠 그리고 제가 신고 있는 제품\n",
      "OpenAI Transcription Time: 1.83 seconds\n",
      "Groq Transcription:  느낌이 확실히 나죠? 그래서 앞코가 조금 더 나는 동그란 타입을 원합니다 하시는 분들은 저희 소가죽 첼시 앵클부츠 그리고 제가 신고 있는 제품\n",
      "Groq Transcription Time: 0.54 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  느낌이 확실히 나죠? 그래서 앞코가 조금 더 나는 동그란 타입을 원합니다 하시는 분들은 저희 소가죽 첼시 앵클부츠 그리고 제가 신고 있는 제품\n",
      "Whisper Local Transcription Time: 15.75 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_1.wav...\n",
      "OpenAI Transcription: 앞코가 스퀘어라인으로 빠져있어서 조금 더 트렌디한 느낌이 납니다. 와, 비교 감사드려요 하는데요. 아직 한 가지 차이점이 더 남아있습니다.\n",
      "OpenAI Transcription Time: 1.32 seconds\n",
      "Groq Transcription:  보면 앞코가 스퀘어 라인으로 빠져 있어서 조금 더 트렌디한 느낌이 납니다 우와 비교 감사드려야 하는데요 아직 한 가지 차이점이 더 남아있습니다\n",
      "Groq Transcription Time: 0.68 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  앞코가 스퀘어 라인으로 빠져 있어서 조금 더 트렌디한 느낌이 납니다 우와 비교 감사드려야 하는데요 아직 한 가지 차이점이 더 남아있습니다\n",
      "Whisper Local Transcription Time: 15.08 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_2.wav...\n",
      "OpenAI Transcription: 오예! 제가 신고 있는 제품은 양쪽이 완벽한 첼시 디자인으로 들어가 있는 니팅이 붙어있는 타입이에요. 첼시 부츠라고 하면 가장\n",
      "OpenAI Transcription Time: 1.26 seconds\n",
      "Groq Transcription:  뭐냐 제가 신고 있는 제품은 양쪽이 완벽한 첼시 디자인으로 들어가 있는 니팅이 붙어있는 타입이에요 첼시 부츠라고 하면 가장\n",
      "Groq Transcription Time: 0.69 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  뭐냐? 제가 신고 있는 제품은 양쪽이 완벽한 첼시 디자인으로 들어가 있는 니팅이 붙어있는 타입이에요. 첼시 부츠라고 하면 가장...\n",
      "Whisper Local Transcription Time: 15.04 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_3.wav...\n",
      "OpenAI Transcription: 디자인의 포인트가 될 수 있는 게 이 옆쪽의 디테일이고요. 옆쪽의 디테일 보다는 니트로 들어가 있어서 신고 벗는데 너무 편하시더라고요. 그래서 저는 이렇게 조금 비교를 해봤습니다.\n",
      "OpenAI Transcription Time: 1.24 seconds\n",
      "Groq Transcription:  디자인의 포인트가 될 수 있는 게 이 옆쪽에 디테일이고요 옆쪽에 디테일이 니트로 들어가 있어서 신고 벗는데 너무 편하시더라고요 그래서 저는 이렇게 조금 비교를\n",
      "Groq Transcription Time: 0.56 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  디자인의 포인트가 될 수 있는 게 이 옆쪽에 디테일이고요 옆쪽에 디테일이 니트로 들어가 있어서 신고 벗는데 너무 편하시더라고요 그래서 저는 이렇게 조금 비교를\n",
      "Whisper Local Transcription Time: 15.19 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_4.wav...\n",
      "OpenAI Transcription: 해드릴래요 나는 좀 바지를 많이 입고 저는 조금 트렌디한 걸로 좀 따라가고 싶습니다 하시는 분들은 제가 신고 있는 제품\n",
      "OpenAI Transcription Time: 1.20 seconds\n",
      "Groq Transcription:  나는 바지를 많이 입고 저는 트렌디한 걸로 따라가고 싶습니다 하시는 분들은 제가 신고 있는 제품을\n",
      "Groq Transcription Time: 0.50 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  해드릴래요. 나는 좀 바지를 많이 입고 저는 조금 트렌디한 걸로 좀 따라가고 싶습니다. 하시는 분들은 제가 신고 있는 제품을\n",
      "Whisper Local Transcription Time: 14.99 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_5.wav...\n",
      "OpenAI Transcription: 도움으로 넘어오신다면 청바지에도 예쁘고 뭔가 이렇게 스커트랑 매치해도 세련되고 조금 더 시크한 매력을 느껴가실 수 있는 제품이 아닐까라는 생각이 들었어요.\n",
      "OpenAI Transcription Time: 1.84 seconds\n",
      "Groq Transcription:  도움으로 넘어오신다면 청바지에도 예쁘고 스커트와 매치에도 세련되고 조금 더 시크한 매력을 느껴가실 수 있는 제품이 아닐까 라는 생각이 들어요\n",
      "Groq Transcription Time: 0.61 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  도움으로 넘어오신다면 선바지에도 예쁘고 스커트랑 매치해도 세련되고 조금 더 시크한 매력을 느껴가실 수 있는 제품이 아닐까 라는 생각이 들어요\n",
      "Whisper Local Transcription Time: 15.32 seconds\n",
      "\n",
      "Processing /kaggle/input/audio-benchmark/audio_6.wav...\n",
      "OpenAI Transcription: 이 디자인의 차이 한번 비교해 볼까요?\n",
      "OpenAI Transcription Time: 0.89 seconds\n",
      "Groq Transcription:  그래서 이 디자인의 차이 한번\n",
      "Groq Transcription Time: 0.34 seconds\n",
      "Using device: cuda\n",
      "Whisper Local Transcription:  이 디자인의 차이 한번\n",
      "Whisper Local Transcription Time: 14.85 seconds\n"
     ]
    }
   ],
   "source": [
    "# List of audio file paths\n",
    "audio_files = [f\"/kaggle/input/audio-benchmark/audio_{i}.wav\" for i in range(7)]\n",
    "\n",
    "# Function definitions for OpenAI, Groq, and Whisper transcriptions\n",
    "# Assume these functions are already defined: transcribe_audio_with_openai, transcribe_audio_with_groq, transcribe_audio_with_whisper_local\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for audio_file_path in audio_files:\n",
    "        print(f\"\\nProcessing {audio_file_path}...\")\n",
    "\n",
    "        # Measure time for OpenAI transcription\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            transcription_text = transcribe_audio_with_openai(audio_file_path)\n",
    "            openai_duration = time.time() - start_time\n",
    "            if transcription_text:\n",
    "                print(f\"OpenAI Transcription: {transcription_text}\")\n",
    "            print(f\"OpenAI Transcription Time: {openai_duration:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI Transcription Error: {e}\")\n",
    "\n",
    "        # Measure time for Groq transcription\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            transcription_text_groq = transcribe_audio_with_groq(audio_file_path)\n",
    "            groq_duration = time.time() - start_time\n",
    "            if transcription_text_groq:\n",
    "                print(f\"Groq Transcription: {transcription_text_groq}\")\n",
    "            print(f\"Groq Transcription Time: {groq_duration:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Groq Transcription Error: {e}\")\n",
    "\n",
    "        # Measure time for Whisper local transcription\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            transcription_text_whisper_local = transcribe_audio_with_whisper_local(audio_file_path)\n",
    "            whisper_local_duration = time.time() - start_time\n",
    "            if transcription_text_whisper_local:\n",
    "                print(f\"Whisper Local Transcription: {transcription_text_whisper_local}\")\n",
    "            print(f\"Whisper Local Transcription Time: {whisper_local_duration:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            print(f\"Whisper Local Transcription Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6308479,
     "sourceId": 10207649,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
